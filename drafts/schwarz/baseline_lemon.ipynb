{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c96e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import mne\n",
    "import pathlib\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torcheeg\n",
    "import xgboost\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09732bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/u/home/swth/brain-age/drafts/schwarz')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path().resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415db60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d939af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./HBN_R10_Pheno.csv', <http.client.HTTPMessage at 0x7f87aae50ca0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"http://fcon_1000.projects.nitrc.org/indi/cmi_healthy_brain_network/File/_pheno/HBN_R10_Pheno.csv\", \"./HBN_R10_Pheno.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d8c8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NDARJK487UCN\n",
       "1      NDARFW670TY2\n",
       "2      NDARHU395FP0\n",
       "3      NDARHV885JFU\n",
       "4      NDARCP753UEW\n",
       "           ...     \n",
       "847    NDARUP748AXG\n",
       "848    NDARYE131DBX\n",
       "849    NDARMG355BP1\n",
       "850    NDARZC445DDK\n",
       "851    NDAREK130FBX\n",
       "Name: EID, Length: 852, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./HBN_R10_Pheno.csv\").EID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ef0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpolateElectrodes(object):\n",
    "    \"\"\"\n",
    "    interpolates between electrodes recomputing the interpolation matrix for each sample\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, from_montage, to_montage):\n",
    "\n",
    "        ### Get interpolation matrix given several mne montage (covering all channels of interest)\n",
    "\n",
    "        self.from_ch_pos = np.stack(\n",
    "            [value for key, value in from_montage.get_positions()[\"ch_pos\"].items()]\n",
    "        )\n",
    "        self.to_ch_pos = np.stack(\n",
    "            [value for key, value in to_montage.get_positions()[\"ch_pos\"].items()]\n",
    "        )   \n",
    "    def __call__(self, x):\n",
    "        interpolation_matrix = mne.channels.interpolation._make_interpolation_matrix(\n",
    "                self.from_ch_pos, self.to_ch_pos\n",
    "                )\n",
    "        x_interpolated = np.matmul(interpolation_matrix, x)\n",
    "        return x_interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b6af0d",
   "metadata": {},
   "source": [
    "### Interface with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee7d11a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data_dir\u001b[38;5;241m.\u001b[39mis_dir()\n\u001b[1;32m      4\u001b[0m data_dir_healthy \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhealthy_controls/preprocessed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data_dir_healthy\u001b[38;5;241m.\u001b[39mis_dir()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(\"../../data/\")\n",
    "assert data_dir.is_dir()\n",
    "\n",
    "data_dir_healthy = data_dir / \"healthy_controls/preprocessed\"\n",
    "assert data_dir_healthy.is_dir()\n",
    "\n",
    "data_dir_chronic_pain = data_dir / \"chronic_pain_patients\"\n",
    "assert data_dir_chronic_pain.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_files_all = list(data_dir.rglob(\"*.vhdr\"))\n",
    "\n",
    "eeg_files_raw = [f for f in eeg_files_all if not \"preprocessed\" in str(f)]\n",
    "eeg_files_preprocessed = [f for f in eeg_files_all if \"preprocessed\" in str(f)]\n",
    "\n",
    "eeg_files_healthy = list(data_dir_healthy.rglob(\"*.vhdr\"))\n",
    "eeg_files_chronic_pain = [f for f in eeg_files_preprocessed if \"chronic_pain_patients\" in str(f)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713fc9fa",
   "metadata": {},
   "source": [
    "### Analyze the subject data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7a4ac6",
   "metadata": {},
   "source": [
    "#### Load clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a3e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_subj = data_dir / \"clinical_data_updated_2020-08-04.ods\"\n",
    "assert f_subj.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0675da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subj_chronic_pain = pd.read_excel(f_subj, sheet_name=0, engine=\"odf\", skiprows=1)\n",
    "df_subj_healthy = pd.read_excel(f_subj, sheet_name=1, engine=\"odf\", skiprows=0)\n",
    "\n",
    "df_subj = pd.concat([df_subj_chronic_pain, df_subj_healthy])\n",
    "df_subj[\"Age(years)\"] = df_subj[\"Age(years)\"].fillna(df_subj[\"Age (years)\"])\n",
    "\n",
    "print(f\"# recorded subjects:      {len(df_subj)}\")\n",
    "print(f\"# raw eeg files:          {len(eeg_files_raw)}\")\n",
    "print(f\"# preprocessed eeg files: {len(eeg_files_preprocessed)}\")\n",
    "\n",
    "zfill_ints = lambda x:str(x).zfill(3) if type(x) else x\n",
    "df_subj_chronic_pain[\"Subject ID\"] = df_subj_chronic_pain[\"Subject ID\"].astype(str).map(zfill_ints)\n",
    "df_subj_healthy[\"Subject ID\"] = df_subj_healthy[\"Subject ID\"].astype(str).map(zfill_ints)\n",
    "df_subj[\"Subject ID\"] = df_subj[\"Subject ID\"].astype(str).map(zfill_ints)\n",
    "\n",
    "df_subj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ae5e0",
   "metadata": {},
   "source": [
    "#### Check the metadata and set channel types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b7e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_raw = mne.io.read_raw_brainvision(eeg_files_chronic_pain[0])\n",
    "example_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca942a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_to_channel_type = {ch_name:\"eeg\" for ch_name in example_raw.ch_names}\n",
    "channel_to_channel_type.update({\"LE\":\"misc\", \"RE\":\"misc\"})\n",
    "eeg_chs = [ch for ch in example_raw.ch_names if not (ch==\"RE\" or ch==\"LE\")]\n",
    "example_raw.set_channel_types(channel_to_channel_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9f238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "example_raw = example_raw.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022682da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in eeg_files_preprocessed:\n",
    "    if not f.is_file():\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726b5a36",
   "metadata": {},
   "source": [
    "### Extract PSD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subj_id(eeg_file: pathlib.Path):\n",
    "    return eeg_file.stem.split(\"_\")[-3]\n",
    "\n",
    "def get_age(df_subj, eeg_file: pathlib.Path):\n",
    "    subj_id = get_subj_id(eeg_file)\n",
    "    return df_subj[df_subj[\"Subject ID\"] == subj_id][\"Age(years)\"].values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0fc19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ages = []\n",
    "psds = []\n",
    "\n",
    "for f in eeg_files_preprocessed:\n",
    "    \n",
    "    age = get_age(df_subj, f)\n",
    "    raw = mne.io.read_raw_brainvision(f, verbose=False, preload=True)\n",
    "    raw = raw.set_channel_types(channel_to_channel_type, verbose=False)\n",
    "    raw = raw.notch_filter(freqs=50, notch_widths=0.5)\n",
    "    raw = raw.filter(l_freq=1, h_freq=100)\n",
    "    ages.append(age)\n",
    "    psds.append(np.log(raw.compute_psd().get_data()))\n",
    "    \n",
    "psds = np.stack(psds)\n",
    "ages = np.array(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, cross_val_score, KFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105d8af6",
   "metadata": {},
   "source": [
    "### Baselines with train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_name_to_ch_pos = montage.get_positions()[\"ch_pos\"]\n",
    "\n",
    "pos = [ch_name_to_ch_pos[ch_name] for ch_name in example_raw.ch_names if channel_to_channel_type[ch_name]==\"eeg\"]\n",
    "pos = np.stack(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = psds.reshape(len(psds), -1), ages\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=0.66)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "rfg = RandomForestRegressor()\n",
    "rfg.fit(X_train, y_train)\n",
    "r_squared_rfg_train = rfg.score(scaler.transform(X_train), y_train)\n",
    "r_squared_rfg_val = rfg.score(scaler.transform(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc352d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# percent_feat = 0.5\n",
    "# feat_mask = rfg.feature_importances_ > np.percentile(rfg.feature_importances_, 100-percent_feat)\n",
    "# X_train = X_train[:, feat_mask]\n",
    "# X_val = X_val[:, feat_mask]\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators=400)\n",
    "gbr.fit(X_train, y_train)\n",
    "r_squared_gbr_train = gbr.score(scaler.transform(X_train), y_train)\n",
    "r_squared_gbr_val = gbr.score(scaler.transform(X_val), y_val)\n",
    "\n",
    "print(\"\\nTraining performance (R²) \\n\")\n",
    "print(f\"random forest regressor:     {r_squared_rfg_train:.3}\")\n",
    "print(f\"gradient boosting regressor: {r_squared_gbr_train:.3}\")\n",
    "print(\"\\nValidation performance (R²) \\n\")\n",
    "print(f\"random forest regressor:     {r_squared_rfg_val:.3}\")\n",
    "print(f\"gradient boosting regressor: {r_squared_gbr_val:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b78e3",
   "metadata": {},
   "source": [
    "### KFold Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = psds.reshape(len(psds), -1), ages\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfg = RandomForestRegressor()\n",
    "rfg_pipe = Pipeline(steps=[(\"scaler\", scaler), (\"rfg\", rfg)])\n",
    "\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "r_squared_rfg_val = cross_val_score(rfg_pipe, X=X_train, y=y_train, scoring='r2', cv=cv, n_jobs=-1)\n",
    "r_squared_rfg_val_mean, r_squared_rfg_val_std = r_squared_rfg_val.mean(), r_squared_rfg_val.std()\n",
    "\n",
    "print(f\"{r_squared_rfg_val_mean:.3} +/- {r_squared_rfg_val_std:.3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor()\n",
    "gbr_pipe = Pipeline(steps=[(\"scaler\", scaler), (\"gbr\", gbr)])\n",
    "\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "r_squared_gbr_val = cross_val_score(gbr_pipe, X=X_train, y=y_train, scoring='r2', cv=cv, n_jobs=-1)\n",
    "r_squared_gbr_val_mean, r_squared_gbr_val_std = r_squared_gbr_val.mean(), r_squared_gbr_val.std()\n",
    "\n",
    "print(f\"{r_squared_gbr_val_mean:.3} +/- {r_squared_gbr_val_std:.3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32999267",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(n_estimators=160, max_depth=2, learning_rate=0.1)\n",
    "xgbr_pipe = Pipeline(steps=[(\"scaler\", scaler), (\"xgbr\", xgbr)])\n",
    "\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "r_squared_xgbr_val = cross_val_score(xgbr_pipe, X=X_train, y=y_train, scoring='r2', cv=cv, n_jobs=-1)\n",
    "r_squared_xgbr_val_mean, r_squared_xgbr_val_std = r_squared_xgbr_val.mean(), r_squared_xgbr_val.std()\n",
    "\n",
    "print(f\"{r_squared_xgbr_val_mean:.3} +/- {r_squared_xgbr_val_std:.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08035459",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556ec3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3ca9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    \"xg_gbr__n_estimators\": [20, 80, 160, 320, 640, 1280],\n",
    "    \"xg_gbr__max_depth\": [2, 3, 4, 5, 6],\n",
    "    \"xg_gbr__learning_rate\": [1e-3, 1e-2, 1e-1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_regr = XGBRegressor()\n",
    "xgb_pipe = Pipeline(steps=[(\"scaler\", scaler), (\"xg_gbr\", xgb_regr)])\n",
    "\n",
    "inner_cv = KFold(n_splits=10)\n",
    "outer_cv = KFold(n_splits=10)\n",
    "\n",
    "xgb_regr_cv = RandomizedSearchCV(xgb_pipe, param_distributions, cv=inner_cv, n_iter=10)\n",
    "search = xgb_regr_cv.fit(X_train, y_train)\n",
    "\n",
    "r_squared_xgbr_train = xgb_regr_cv.best_score_\n",
    "r_squared_xgbr_val = cross_val_score(xgb_regr_cv, X=X_train, y=y_train, scoring='r2', cv=outer_cv)\n",
    "\n",
    "print(\n",
    "    r_squared_xgbr_train,\n",
    "    r_squared_xgbr_val.mean(),\n",
    "    r_squared_xgbr_val.std()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c818e29",
   "metadata": {},
   "source": [
    "### Neural network baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb04e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.models import EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_to_channel_type = {ch_name:\"eeg\" for ch_name in raw.ch_names}\n",
    "channel_to_channel_type.update({\"LE\":\"misc\", \"RE\":\"misc\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b413c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 300\n",
    "epoch_len = sfreq * 10\n",
    "\n",
    "epochs = []\n",
    "ages = []\n",
    "\n",
    "for f in eeg_files_preprocessed:\n",
    "    \n",
    "    sub_id = get_subj_id(f)\n",
    "    age = get_age(df_subj, f)\n",
    "    raw = mne.io.read_raw_brainvision(f, verbose=False, preload=True)\n",
    "    \n",
    "    raw.set_channel_types(channel_to_channel_type)\n",
    "    raw = raw.crop(raw.tmin+30, raw.tmax-30)\n",
    "    raw = raw.filter(l_freq=0.5, h_freq=100)\n",
    "    raw = raw.notch_filter(freqs=50, notch_widths=0.5)\n",
    "\n",
    "    raw = raw.resample(sfreq=sfreq)\n",
    "    data = raw.get_data(picks=eeg_chs)\n",
    "    \n",
    "    sections = np.arange(0, data.shape[-1], epoch_len)\n",
    "    epochs_subj = np.split(data, sections, axis=1)[1:-1]\n",
    "    \n",
    "    epochs.append(epochs_subj)\n",
    "    ages.append(len(epochs_subj)*[age])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6808c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_eegnet = {\n",
    "    \"learning_rate\":1e-3,\n",
    "    \"batch_size\":64,\n",
    "    \"dropout\":0.5,\n",
    "    \"kernel_1\":150,\n",
    "    \"kernel_2\":16,\n",
    "    \"F1\":8,\n",
    "    \"F2\":8,\n",
    "    \"depth_multiplier\":2\n",
    "}\n",
    "\n",
    "eegnet = EEGNet(chunk_size=epoch_len,\n",
    "               num_electrodes=63,\n",
    "               dropout=hparams_eegnet[\"dropout\"],\n",
    "               kernel_1=hparams_eegnet[\"kernel_1\"],\n",
    "               kernel_2=hparams_eegnet[\"kernel_2\"],\n",
    "               F1=hparams_eegnet[\"F1\"],\n",
    "               F2=hparams_eegnet[\"F2\"],\n",
    "               D=hparams_eegnet[\"depth_multiplier\"],\n",
    "               num_classes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe2e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80228d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _totensor(x):\n",
    "    return torch.tensor(x).float()\n",
    "\n",
    "def _channelwise_norm(x):\n",
    "    return (x - x.mean(-1, keepdims=True)) / x.std(-1, keepdims=True)\n",
    "\n",
    "def _toimshape(x):\n",
    "    return x.unsqueeze(0)\n",
    "\n",
    "def _compose(x, transforms):\n",
    "    for transform in transforms:\n",
    "        x = transform(x)\n",
    "    return x\n",
    "\n",
    "def _labelcenter(x, mean_age):\n",
    "    return x - mean_age\n",
    "\n",
    "_labelcenter = partial(_labelcenter, mean_age=df_subj[\"Age(years)\"].mean())\n",
    "transforms = partial(_compose, transforms=[_totensor, _channelwise_norm, _toimshape])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dde145",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainAgeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, epochs, ages, transforms=lambda x:x, target_transforms=lambda x:x):\n",
    "        self.epochs = epochs\n",
    "        self.ages = ages\n",
    "        self.transforms = transforms\n",
    "        self.target_transforms = target_transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transforms(self.epochs[idx]), self.target_transforms(self.ages[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40dcfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(epochs)\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(ages)\n",
    "\n",
    "n_train = int(0.8*len(epochs))\n",
    "\n",
    "epochs_train = epochs[:n_train]\n",
    "ages_train = ages[:n_train]\n",
    "\n",
    "epochs_val = epochs[n_train:]\n",
    "ages_val = ages[n_train:]\n",
    "\n",
    "dataset_train = BrainAgeDataset(np.concatenate(epochs_train), np.concatenate(ages_train), \n",
    "                                transforms=transforms, target_transforms=_labelcenter)\n",
    "dataset_val = BrainAgeDataset(np.concatenate(epochs_val), np.concatenate(ages_val), \n",
    "                              transforms=transforms, target_transforms=_labelcenter)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=hparams_eegnet[\"batch_size\"], drop_last=True)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=hparams_eegnet[\"batch_size\"], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95c54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.concatenate(epochs)), len(np.concatenate(ages)), \\\n",
    "len(np.concatenate(epochs_train)), len(np.concatenate(ages_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainAgeModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model, hparams):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.hparams.hparams[\"learning_rate\"])\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        val_loss = torch.nn.functional.l1_loss(y.squeeze(), y_hat)\n",
    "        self.log(\"validation loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = torch.nn.functional.l1_loss(y.squeeze(), y_hat)\n",
    "        self.log(\"training loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ba048",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BrainAgeModel(list(eegnet.modules())[0], hparams_eegnet)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f560203",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b53c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2(model, val_dataloader):\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "    rss = 0\n",
    "    tss = 0\n",
    "    n = 0\n",
    "    for batch in val_dataloader:\n",
    "        x, y = batch\n",
    "        y_hat = model.forward(x)\n",
    "        rss += torch.nn.functional.mse_loss(y.squeeze(), y_hat.squeeze())\n",
    "        tss += y.var()\n",
    "#         n += len(y)\n",
    "    return 1 - rss/tss    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5e736",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "wandb.login()\n",
    "logger = pl.loggers.WandbLogger(project=\"brain-age-ssl\", name=\"EEGNet baseline on 1.0 batches\", \n",
    "                                save_dir=\"/data0/practical-sose23/brain-age\", log_model=False)\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"validation loss\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
    "\n",
    "trainer = pl.Trainer(callbacks=[early_stop_callback], overfit_batches=1.0, max_epochs=200, accelerator=\"gpu\", logger=logger)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15c1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_r2(model, dataloader_val), \\\n",
    "compute_r2(model, dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8609b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
